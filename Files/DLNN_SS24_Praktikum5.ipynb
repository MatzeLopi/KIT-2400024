{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "221abf0f",
      "metadata": {
        "id": "221abf0f"
      },
      "source": [
        "# Praktikum 5 - Large Language Model\n",
        "\n",
        "Note: the praktikums are for your own practice. They will **not be graded**!\n",
        "\n",
        "Remember to make a copy of this notebook to your own Colab. Changes made directly here will not be stored!\n",
        "\n",
        "Whenenver you see an ellipsis `...` and/or TODO comment, you're supposed to insert code or text answers.\n",
        "\n",
        "\n",
        "\n",
        "In this praktikum we will walk you through how to work with large language models.\n",
        "\n",
        "We will use large language model to solve the task of Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1216ca5",
      "metadata": {
        "id": "e1216ca5"
      },
      "source": [
        "## Using LLMs with OpenAI API\n",
        "\n",
        "One way of using LLMs is via the OpenAI API.\n",
        "\n",
        "The OpenAI API can be used to access LLMs hosted using the [Text Generation Inference by Huggingface](https://huggingface.co/docs/text-generation-inference/en/index), [llama.cpp](https://github.com/ggerganov/llama.cpp), and OpenAI's models (you would have to pay to use this one), ...\n",
        "\n",
        "For this praktikum, I have hosted an LLM in our server, which you can access via the OpenAI API. The LLM used is [Mistral-7B-Instruct-v0.2](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2).\n",
        "\n",
        "First, we need to install OpenAI:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "133e18c9",
      "metadata": {
        "id": "133e18c9"
      },
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a26593e5",
      "metadata": {
        "id": "a26593e5"
      },
      "source": [
        "Then, create a `client`. Since you are using my hosted LLM, you do not need an OpenAI API key, and you need to specify the `base_url` to be the location where I host the LLM:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "842afc2a",
      "metadata": {
        "id": "842afc2a"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "api_key = \"we_dont_need_this\"\n",
        "base_url=\"https://i13hpc51.isl.iar.kit.edu/v1\"\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=base_url,\n",
        "    timeout=900,\n",
        "    api_key=api_key\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96c91e7c",
      "metadata": {
        "id": "96c91e7c"
      },
      "source": [
        "Let's try sending your first request!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d02d391",
      "metadata": {
        "id": "8d02d391"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"mistral\",\n",
        "    seed=0,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"What's the weather like today?\"}\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "353f6a2b",
      "metadata": {
        "id": "353f6a2b"
      },
      "source": [
        "Inpect the output:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f317fab7",
      "metadata": {
        "id": "f317fab7"
      },
      "outputs": [],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d52c811",
      "metadata": {
        "id": "9d52c811"
      },
      "source": [
        "Extract the response content:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf1851f0",
      "metadata": {
        "id": "bf1851f0"
      },
      "outputs": [],
      "source": [
        "response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cec9784e",
      "metadata": {
        "id": "cec9784e"
      },
      "source": [
        "## Task: Sentiment Analysis\n",
        "\n",
        "We will work on the task of Sentiment Analysis. Specifically, we will make use of the [Multiclass Sentiment Analysis Dataset](https://huggingface.co/datasets/Sp1786/multiclass-sentiment-analysis-dataset), which contains English sentences and their corresponding sentiment labels among `[positive, negative, neutral]`.\n",
        "\n",
        "First, download and load the dataset. We will truncate this dataset for faster inference speed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29a9dde3",
      "metadata": {
        "id": "29a9dde3"
      },
      "outputs": [],
      "source": [
        "!wget https://bwsyncandshare.kit.edu/s/M5sDCcBrf8earHk/download/Sp1786--multiclass-sentiment-analysis-dataset.zip\n",
        "!unzip Sp1786--multiclass-sentiment-analysis-dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70a5c46b",
      "metadata": {
        "id": "70a5c46b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "train_df = pd.read_csv(\"Sp1786--multiclass-sentiment-analysis-dataset/train_df.csv\")\n",
        "test_df = pd.read_csv(\"Sp1786--multiclass-sentiment-analysis-dataset/test_df.csv\")[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7098fd22",
      "metadata": {
        "id": "7098fd22"
      },
      "source": [
        "Inspect the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f52a287c",
      "metadata": {
        "id": "f52a287c"
      },
      "outputs": [],
      "source": [
        "test_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a36ac37b",
      "metadata": {
        "id": "a36ac37b"
      },
      "source": [
        "## LLM for Sentiment Analysis\n",
        "\n",
        "We will now see how we can make use of the LLM for Sentiment Analysis. As the most naive approach, we can try directly asking the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c052d8f6",
      "metadata": {
        "id": "c052d8f6"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"mistral\",\n",
        "    seed=0,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"What is the sentiment of this sentence: \"\\\n",
        "                       \"\\\"getting cds ready for tour\\\"? \" \\\n",
        "                       \"The sentiment is one of the followings: positive, negative, neutral\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ace03105",
      "metadata": {
        "id": "ace03105"
      },
      "source": [
        "As you can see, the answer from the LLM is freeform. Therefore, we need to extract the sentiment labels from this freeform answer. Fill in the function below for this purpose:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f76c09cc",
      "metadata": {
        "id": "f76c09cc"
      },
      "outputs": [],
      "source": [
        "def extract_label(llm_output):\n",
        "    ...\n",
        "\n",
        "extract_label(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af2472fc",
      "metadata": {
        "id": "af2472fc"
      },
      "source": [
        "Let's now do the inference more systematically. Let's define a function where we can input an English sentence, and get LLM answer out. Feel free to re-design your prompt, i.e., asking the LLM in a different way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1f376f8",
      "metadata": {
        "id": "b1f376f8"
      },
      "outputs": [],
      "source": [
        "def llm_sa(en_sent):\n",
        "    ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74202221",
      "metadata": {
        "id": "74202221"
      },
      "outputs": [],
      "source": [
        "llm_output = test_df['text'].apply(lambda x: llm_sa(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c59a597",
      "metadata": {
        "id": "1c59a597"
      },
      "source": [
        "Now, let's evaluate the performance of the LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66596037",
      "metadata": {
        "id": "66596037"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# First extract the labels from the LLM's answer\n",
        "llm_labels = llm_output.apply(lambda x: extract_label(x))\n",
        "\n",
        "print(metrics.accuracy_score(test_df['label'], llm_labels))\n",
        "print(metrics.f1_score(test_df['label'], llm_labels, average='micro'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc36f697",
      "metadata": {
        "id": "fc36f697"
      },
      "source": [
        "## In-context learning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8d0acda",
      "metadata": {
        "id": "f8d0acda"
      },
      "source": [
        "In order to improve the performance of the LLM, we can provide it with some examples. This is called *In-context Learning*, or *Few-shot Prompting*.\n",
        "\n",
        "First, write the function to select the examples fromt the training data. We will try out 3 different strategies:\n",
        "- Select the examples randomly\n",
        "- Select the most similar examples using a transformer sentence embedding model\n",
        "- Select the most similar examples using a traditional metric, e.g., CHRF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cac1855c",
      "metadata": {
        "id": "cac1855c"
      },
      "outputs": [],
      "source": [
        "!pip install -U sentence-transformers\n",
        "!pip install sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6da6b97b",
      "metadata": {
        "id": "6da6b97b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from sacrebleu.metrics import CHRF\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "def select_shot(en_sent, nr_shots, method='random', similarity_model=None):\n",
        "    if method == 'random':\n",
        "        ...\n",
        "    elif method == 'closest_sentences_transformer':\n",
        "        ...\n",
        "    elif method == 'closest_sentences_chrf':\n",
        "        ...\n",
        "    else:\n",
        "        raise NotImplmentedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88ffac0c",
      "metadata": {
        "id": "88ffac0c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d4870a4d",
      "metadata": {
        "id": "d4870a4d"
      },
      "source": [
        "Now write the function to perform LLM inference for Sentiment Analysis with few-shot prompting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37f61744",
      "metadata": {
        "id": "37f61744"
      },
      "outputs": [],
      "source": [
        "def llm_sa_few_shot(en_sent, nr_shots=2, shot_selection_method='random'):\n",
        "    ...\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ceec7797",
      "metadata": {
        "id": "ceec7797"
      },
      "outputs": [],
      "source": [
        "nr_shots = 2\n",
        "\n",
        "for shot_selection_method in ['random', 'closest_sentences_transformer', 'closest_sentences_chrf']:\n",
        "    print(f'shot_selection_method: {shot_selection_method}')\n",
        "    llm_output = test_df['text'].apply(lambda x: llm_sa_few_shot(x, nr_shots))\n",
        "\n",
        "    # First extract the labels from the LLM's answer\n",
        "    llm_labels = llm_output.apply(lambda x: extract_label(x))\n",
        "\n",
        "    print(metrics.accuracy_score(test_df['label'], llm_labels))\n",
        "    print(metrics.f1_score(test_df['label'], llm_labels, average='micro'))\n",
        "    print('------------------------------------------------------')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c64cf564",
      "metadata": {
        "id": "c64cf564"
      },
      "source": [
        "## Chain-of-thought prompting\n",
        "\n",
        "Another way to improve the performance of the LLM is through Chain-of-thought Prompting, i.e., asking the model to first provide the reasoning before giving the final output.\n",
        "\n",
        "Write the function to perform LLM inference for Sentiment Analysis with Chain-of-thought prompting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2cd1fe7",
      "metadata": {
        "id": "c2cd1fe7"
      },
      "outputs": [],
      "source": [
        "def llm_sa_cot(en_sent):\n",
        "    ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6aee0349",
      "metadata": {
        "id": "6aee0349"
      },
      "outputs": [],
      "source": [
        "llm_output = test_df['text'].apply(lambda x: llm_sa_cot(x))\n",
        "\n",
        "# First extract the labels from the LLM's answer\n",
        "llm_labels = llm_output.apply(lambda x: extract_label(x))\n",
        "\n",
        "print(metrics.accuracy_score(test_df['label'], llm_labels))\n",
        "print(metrics.f1_score(test_df['label'], llm_labels, average='micro'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a588a595",
      "metadata": {
        "id": "a588a595"
      },
      "source": [
        "## In-context learning + Chain-of-thought prompting\n",
        "\n",
        "Now let's combine the two methods. Write the function to perform LLM inference for Sentiment Analysis with Few-shot Prompting and Chain-of-thought Prompting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8846dec3",
      "metadata": {
        "id": "8846dec3"
      },
      "outputs": [],
      "source": [
        "def llm_sa_few_shot_cot(en_sent, nr_shots=2):\n",
        "    ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63132c6e",
      "metadata": {
        "id": "63132c6e"
      },
      "outputs": [],
      "source": [
        "nr_shots = 2\n",
        "\n",
        "llm_output = test_df['text'].apply(lambda x: llm_sa_few_shot_cot(x, nr_shots))\n",
        "\n",
        "# First extract the labels from the LLM's answer\n",
        "llm_labels = llm_output.apply(lambda x: extract_label(x))\n",
        "\n",
        "print(metrics.accuracy_score(test_df['label'], llm_labels))\n",
        "print(metrics.f1_score(test_df['label'], llm_labels, average='micro'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d53018ca",
      "metadata": {
        "id": "d53018ca"
      },
      "source": [
        "## LLM attack\n",
        "\n",
        "In this section, we try to attack the LLM and make it output whatever we want. Let's try to make it output \"LLMs are evil.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8ae8962",
      "metadata": {
        "id": "e8ae8962"
      },
      "outputs": [],
      "source": [
        "llm_sa(...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea20a96f",
      "metadata": {
        "id": "ea20a96f"
      },
      "outputs": [],
      "source": [
        "llm_sa_few_shot(...)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67cc7436",
      "metadata": {
        "id": "67cc7436"
      },
      "outputs": [],
      "source": [
        "llm_sa_cot(...)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "102f6a5e",
      "metadata": {
        "id": "102f6a5e"
      },
      "outputs": [],
      "source": [
        "llm_sa_few_shot_cot(...)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86eb204c",
      "metadata": {
        "id": "86eb204c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}