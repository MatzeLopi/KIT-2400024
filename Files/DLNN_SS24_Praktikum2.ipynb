{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "9339153b4e8f400894090f4cdec8212f",
        "deepnote_cell_height": 82,
        "deepnote_cell_type": "markdown",
        "id": "YO8yfcw9g-NJ",
        "tags": []
      },
      "source": [
        "# Praktikum 2 - Transformer\n",
        "\n",
        "Note: the praktikums are for your own practice. They will **not be graded**!\n",
        "\n",
        "You have around one week to work on it. Then we will go over the solutions together in the praktikum time slots!\n",
        "\n",
        "Remember to make a copy of this notebook to your own Colab. Changes made directly here will not be stored!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "eef422cc65524297ab7b1220162873b0",
        "deepnote_cell_type": "text-cell-p",
        "formattedRanges": [],
        "id": "5TOgi_Bzg-NJ",
        "is_collapsed": false,
        "owner_user_id": "175a6e67-5f66-4c81-960a-2a75fbd3d9af",
        "tags": []
      },
      "source": [
        "In this exercise, you'll implement a basic encoder-only Transformer architecture with PyTorch. We will start with building the basic building blocks and then integrate them into a fully-fleged Transformer model.\n",
        "\n",
        "\n",
        "<!-- We train the model to solve a POS-Tagging problem (more on that later). In the previous exercise, you implemented your work in numpy. Now, we will switch to PyTorch, which will track the gradients for us and allows us to focus more on the network itself. -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s471ndsh0612"
      },
      "source": [
        "**Notice**: Whenenver you see an ellipsis `...`, you're supposed to insert code or text answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cell_id": "20b2dbfb9550468d85d409a5a67f64c0",
        "deepnote_cell_height": 149.375,
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 810,
        "execution_start": 1657123567236,
        "id": "sVrK6a2Ug-NK",
        "outputId": "d3695725-a2e8-4f23-abf4-b2cc1c59e977",
        "owner_user_id": "06b28ca6-80fe-4ecd-a509-50438de77bba",
        "source_hash": "2c538688",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-05-14 17:47:11.574764: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-05-14 17:47:11.598662: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-14 17:47:11.598682: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-14 17:47:11.599257: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-05-14 17:47:11.603288: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-05-14 17:47:12.066009: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.15.1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "925794d055334d71a1874bd0928f2358",
        "deepnote_cell_height": 131.1875,
        "deepnote_cell_type": "markdown",
        "id": "TjR2oJyYg-NL",
        "tags": []
      },
      "source": [
        "Let's actually start with a few basic functions that we will need throughout the exercise, namely **Softmax** and **ReLu**.\n",
        "\n",
        "$\\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}$\n",
        "\n",
        "$\\text{ReLU}(x) = \\max(0, x)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "65d60a38ea0d41ca934e8a0f782b1672",
        "deepnote_cell_height": 70,
        "deepnote_cell_type": "markdown",
        "id": "8XMfVcTkg-NL",
        "tags": []
      },
      "source": [
        "## Transformer Block"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "090be921347b4f65a3dd0fca98b29c54",
        "deepnote_cell_height": 178.953125,
        "deepnote_cell_type": "markdown",
        "id": "fVEAAyWqg-NL",
        "tags": []
      },
      "source": [
        "A typical transformer block consists of the following\n",
        "- Multi-Head Attention\n",
        "- Layer Normalization\n",
        "- Linear Layer\n",
        "- Residual Connections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "f87bf87fea1a44bcbc2d5c044843e007",
        "deepnote_cell_height": 353,
        "deepnote_cell_type": "markdown",
        "id": "BTd1mOgog-NL",
        "tags": []
      },
      "source": [
        "<center><img src=\"https://i.imgur.com/ZKgcoe4.png\" alt=\"transformer block visualization\" width=\"200\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "1c8bd5f72db0415bbca4cdd48b0ecd52",
        "deepnote_cell_type": "text-cell-p",
        "formattedRanges": [],
        "id": "nW2ik8r7g-NL",
        "is_collapsed": false,
        "tags": []
      },
      "source": [
        "In the next few subsections, we will build these basic building blocks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "59b1b38243a84b5c9571ddb814cd1a49",
        "deepnote_cell_height": 62,
        "deepnote_cell_type": "markdown",
        "id": "oGRxC5PFg-NL",
        "tags": []
      },
      "source": [
        "### Multi-Head Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "a2a24844affe40a89f26ef6ca0346276",
        "deepnote_cell_height": 88.78125,
        "deepnote_cell_type": "markdown",
        "id": "H0BU5sqdg-NL",
        "tags": []
      },
      "source": [
        "Multi-Head Attention concatenates the outputs of several so called **attention heads**.\n",
        "\n",
        "$\\textrm{MHA}(Q,K,V) = \\textrm{Concat}(H_1,...,H_h)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "ef2e9b876ee44b69a993f15856b206e9",
        "deepnote_cell_height": 376.15625,
        "deepnote_cell_type": "markdown",
        "id": "Y_sx5d4Og-NL",
        "tags": []
      },
      "source": [
        "<center><img src=\"https://www.tensorflow.org/images/tutorials/transformer/multi_head_attention.png\" width=300>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "a045d2caec3e4020a7bb3fee5680442b",
        "deepnote_cell_height": 233.90625,
        "deepnote_cell_type": "markdown",
        "id": "JKGGbtSPg-NL",
        "tags": []
      },
      "source": [
        "One attention head consists of linear projections for each of $Q, K$ and $V$ and an attention mechanism called **Scaled Dot-Product Attention**. The attention mechanism scales down the dot products by $\\sqrt{d_k}$.\n",
        "\n",
        "$\\textrm{Attention}(Q,K,V)=\\textrm{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V$\n",
        "\n",
        "\n",
        "\n",
        "If we assume that $q$ and $v$ are $d_k$-dimensional vectors and its components are independent random variables with mean $0$ and a variance of $d_k$, then their dot product has a mean of $0$ and variance of $d_k$. It is preferred to have a variance of $1$ and that's why we scale them down by $\\sqrt{d_k}$.\n",
        "\n",
        "The dot product $q \\cdot v$ resembles a measure of similarity.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "9495e574d00e4d3798368384c6b3825b",
        "deepnote_cell_height": 421.609375,
        "deepnote_cell_type": "markdown",
        "id": "EpX3rsbmg-NL",
        "tags": []
      },
      "source": [
        "<center><img src=\"https://www.tensorflow.org/images/tutorials/transformer/scaled_attention.png\" width=\"350\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "e3ed8097791f458a85f3aabfd0756d28",
        "deepnote_cell_height": 119.5625,
        "deepnote_cell_type": "markdown",
        "id": "fSpgDtHkg-NL",
        "tags": []
      },
      "source": [
        "Let's start implementing these components. Note that our classes inherit from PyTorch's `nn.Module`. These modules allow us to hold our parameters and easily move them to the GPU (with `.to(...)`). It also let's us define the computation that is performed at every call, in the `forward()` method. For example, when we have an `Attention` module, initialize it like `attention = Attention(...)`, we are able to call it with `attention(Q, K, V)` (it'll execute the `forward` function in an optimized way)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "96fa5effdd954c498f1efa8cd0580bc3",
        "deepnote_cell_height": 62,
        "deepnote_cell_type": "markdown",
        "id": "qECREjDKg-NM",
        "tags": []
      },
      "source": [
        "### Layer Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "fba0740f863c4787aa23494388944b49",
        "deepnote_cell_height": 141.953125,
        "deepnote_cell_type": "markdown",
        "id": "9RDdbMIag-NM",
        "tags": []
      },
      "source": [
        "Layer normalization is when the values are normalized across the feature dimension, independently for each sample in the batch. For that, first calculate mean and standard-deviation across the feature dimension and then scale them appropriately such that the mean is 0 and the standard deviation is 1. Introduce **two sets of learnable parameters**, one for shifting the mean (addition) and one for scaling the variance (multiplication) the normalized features (i.e., two parameters for each feature). Tip: Use `nn.Parameter` for that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5b0e5f8055a945929dd74b990ecd2a89",
        "deepnote_cell_height": 91.5,
        "deepnote_cell_type": "markdown",
        "id": "BULHLwVBg-NM",
        "tags": []
      },
      "source": [
        "$y_{\\textrm{norm}}=\\frac{x-\\mu}{\\sqrt{\\sigma+\\epsilon}}$\n",
        "\n",
        "$y=y_{\\textrm{norm}}\\cdot\\beta+\\alpha$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "f96e811cce6d457f85eead1edae4692f",
        "deepnote_cell_height": 92.390625,
        "deepnote_cell_type": "markdown",
        "id": "TnL2XBOGg-NM",
        "tags": []
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.stack.imgur.com/E3104.png\" alt=\"visualization of layer norm vs. batch norm\" width=\"420\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "246bb7a8b64f4596b26778aa9ce5bc85",
        "deepnote_cell_height": 62,
        "deepnote_cell_type": "markdown",
        "id": "MirW6JCAg-NM",
        "tags": []
      },
      "source": [
        "### Transformer Block"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "93c32b55767c46049ffb13bc012bb500",
        "deepnote_cell_height": 52.390625,
        "deepnote_cell_type": "markdown",
        "id": "iHMXP6nHg-NM",
        "tags": []
      },
      "source": [
        "Here, we bring all ingredients together into a single module. Don't forget to add the residual connections. Let's use a 2-layer MLP with ReLU activation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5HcIuJTKHCiq"
      },
      "outputs": [],
      "source": [
        "def transformer_block(hidden_n:int, h:int = 2, emd_n:int = 128):\n",
        "    \"\"\"_summary_\n",
        "\n",
        "    Args:\n",
        "        hidden_n (int): _description_\n",
        "        h (int, optional): _description_. Defaults to 2.\n",
        "\n",
        "    Returns:\n",
        "        _type_: _description_\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # Nicht richtig... \n",
        "    input_layer = layers.InputLayer()\n",
        "    x = layers.Attention(hidden_n)(input_layer) # Attention layer braucht Key, Value und Query\n",
        "    x = layers.MultiHeadAttention(hidden_n, h)(x)\n",
        "    x = layers.LayerNormalization()(x)\n",
        "    x = layers.Dense(hidden_n, activation='relu')(x)\n",
        "    output_layer = layers.Dense(emd_n, activation='relu')(x)\n",
        "\n",
        "    model = keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "add8b0cdf6ef4a79bf2a71788029d617",
        "deepnote_cell_height": 70,
        "deepnote_cell_type": "markdown",
        "id": "voJMCeBmg-NM",
        "tags": []
      },
      "source": [
        "## A Simple Transformer Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "0215525d6258493485ff71f3496128a2",
        "deepnote_cell_height": 74.78125,
        "deepnote_cell_type": "markdown",
        "id": "2G8hVCmvg-NM",
        "tags": []
      },
      "source": [
        "Let's stack our transformer blocks and add an embedding layer for a simple transformer architecture. You are allowed to use `nn.Embedding` here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cell_id": "613b3d3f1e7145ba8ea535c0a34a66a5",
        "deepnote_cell_height": 277,
        "deepnote_cell_type": "code",
        "id": "oPkbLQjyg-NM",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def stacl_transformer(emb_n: int, hidden_n: int, n:int =3, h:int =2):\n",
        "    \"\"\"_summary_\n",
        "\n",
        "    Args:\n",
        "        emb_n (int): Number of embeddings.\n",
        "        hidden_n (int): Number of neurons in the hidden layer.\n",
        "        n (int, optional): Number of layers. Defaults to 3.\n",
        "        h (int, optional): Number of heads for Multihead attention layer. Defaults to 2.\n",
        "\n",
        "    Returns:\n",
        "        _type_: _description_\n",
        "    \"\"\"\n",
        "\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    for _ in range(n):\n",
        "        model.add(transformer_block(hidden_n, h, emd_n=emb_n))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "24ce63a017054111a0e7606078f244eb",
        "deepnote_cell_type": "text-cell-h2",
        "formattedRanges": [],
        "id": "eEcKB-TOg-NN",
        "is_collapsed": false,
        "tags": []
      },
      "source": [
        "## POS-Tagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "46e6832e31434597932051c2d7d833db",
        "deepnote_cell_height": 74.78125,
        "deepnote_cell_type": "markdown",
        "id": "GA6K1Ohxg-NN",
        "tags": []
      },
      "source": [
        "Part-Of-Speech-Tagging (**POS-Tagging**) is a **sequence labeling problem** where we categorize words in a text in correspondence with a particular part of speech (e.g., \"noun\" or \"adjective\"). A few examples and classes are shown in the following table:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "0b933b07b931423dae80af31abe46b69",
        "deepnote_cell_height": 200.734375,
        "deepnote_cell_type": "markdown",
        "id": "lQImsUJDg-NN",
        "tags": []
      },
      "source": [
        "|  POS Tag  |  Description  |  Examples  |\n",
        "|-----------|------------|------------|\n",
        "|  NN | Noun (singular, common) | mass, wind, ...  |\n",
        "|  NNP | Noun (singular, proper) | Obama, Liverpool, ...  |\n",
        "| CD  | Numeral (cardinal)  | 1890, 0.5, ...  |\n",
        "|  DT | Determiner  | all, any, ... |\n",
        "| JJ | Adjective (ordinal) | oiled, third, ... |\n",
        "... many more"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "c1ea426748d34a2891270fb4c9189387",
        "deepnote_cell_type": "text-cell-h3",
        "formattedRanges": [],
        "id": "KbJ-P7_tg-NN",
        "is_collapsed": false,
        "tags": []
      },
      "source": [
        "### CoNLL2000 Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "ec19498428f042a09867d13bfcbbeaf1",
        "deepnote_cell_height": 52.390625,
        "deepnote_cell_type": "markdown",
        "id": "9BhWiVRwg-NN",
        "tags": []
      },
      "source": [
        "Let's load our dataset which is the **CoNLL2000 dataset** and look at an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cell_id": "56f8d97328eb45808c642c232c18ddeb",
        "deepnote_cell_height": 329.375,
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 3449,
        "execution_start": 1657123575378,
        "id": "PhCtZ0Ygg-NN",
        "outputId": "ee561fdc-ac6c-478c-ce10-2bb8b7bba91f",
        "source_hash": "c7ccc53b",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/matze/miniconda3/envs/tf/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/home/matze/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow_datasets/core/dataset_builders/huggingface_dataset_builder.py:160: FutureWarning: list_datasets is deprecated and will be removed in the next major version of datasets. Use 'huggingface_hub.list_datasets' instead.\n",
            "  hf_names = hf_datasets.list_datasets()\n",
            "2024-05-14 17:48:46.334855: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-05-14 17:48:46.352792: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-05-14 17:48:46.352830: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-05-14 17:48:46.354873: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-05-14 17:48:46.354907: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-05-14 17:48:46.354921: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-05-14 17:48:46.469370: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-05-14 17:48:46.469412: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-05-14 17:48:46.469417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
            "2024-05-14 17:48:46.469440: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-05-14 17:48:46.469451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13553 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chunk_tags</th>\n",
              "      <th>id</th>\n",
              "      <th>pos_tags</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(tf.Tensor(11, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>tf.Tensor(b'0', shape=(), dtype=string)</td>\n",
              "      <td>(tf.Tensor(19, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>(tf.Tensor(b'Confidence', shape=(), dtype=stri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(tf.Tensor(0, shape=(), dtype=int64), tf.Tenso...</td>\n",
              "      <td>tf.Tensor(b'1', shape=(), dtype=string)</td>\n",
              "      <td>(tf.Tensor(20, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>(tf.Tensor(b'Chancellor', shape=(), dtype=stri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(tf.Tensor(0, shape=(), dtype=int64), tf.Tenso...</td>\n",
              "      <td>tf.Tensor(b'2', shape=(), dtype=string)</td>\n",
              "      <td>(tf.Tensor(9, shape=(), dtype=int64), tf.Tenso...</td>\n",
              "      <td>(tf.Tensor(b'But', shape=(), dtype=string), tf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(tf.Tensor(11, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>tf.Tensor(b'3', shape=(), dtype=string)</td>\n",
              "      <td>(tf.Tensor(11, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>(tf.Tensor(b'This', shape=(), dtype=string), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(tf.Tensor(0, shape=(), dtype=int64), tf.Tenso...</td>\n",
              "      <td>tf.Tensor(b'4', shape=(), dtype=string)</td>\n",
              "      <td>(tf.Tensor(8, shape=(), dtype=int64), tf.Tenso...</td>\n",
              "      <td>(tf.Tensor(b'``', shape=(), dtype=string), tf....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>(tf.Tensor(17, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>tf.Tensor(b'95', shape=(), dtype=string)</td>\n",
              "      <td>(tf.Tensor(14, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>(tf.Tensor(b'After', shape=(), dtype=string), ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>(tf.Tensor(11, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>tf.Tensor(b'96', shape=(), dtype=string)</td>\n",
              "      <td>(tf.Tensor(25, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>(tf.Tensor(b'We', shape=(), dtype=string), tf....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>(tf.Tensor(11, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>tf.Tensor(b'97', shape=(), dtype=string)</td>\n",
              "      <td>(tf.Tensor(11, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>(tf.Tensor(b'No', shape=(), dtype=string), tf....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>(tf.Tensor(11, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>tf.Tensor(b'98', shape=(), dtype=string)</td>\n",
              "      <td>(tf.Tensor(11, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>(tf.Tensor(b'The', shape=(), dtype=string), tf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>(tf.Tensor(13, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>tf.Tensor(b'99', shape=(), dtype=string)</td>\n",
              "      <td>(tf.Tensor(14, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>(tf.Tensor(b'Over', shape=(), dtype=string), t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           chunk_tags  \\\n",
              "0   (tf.Tensor(11, shape=(), dtype=int64), tf.Tens...   \n",
              "1   (tf.Tensor(0, shape=(), dtype=int64), tf.Tenso...   \n",
              "2   (tf.Tensor(0, shape=(), dtype=int64), tf.Tenso...   \n",
              "3   (tf.Tensor(11, shape=(), dtype=int64), tf.Tens...   \n",
              "4   (tf.Tensor(0, shape=(), dtype=int64), tf.Tenso...   \n",
              "..                                                ...   \n",
              "95  (tf.Tensor(17, shape=(), dtype=int64), tf.Tens...   \n",
              "96  (tf.Tensor(11, shape=(), dtype=int64), tf.Tens...   \n",
              "97  (tf.Tensor(11, shape=(), dtype=int64), tf.Tens...   \n",
              "98  (tf.Tensor(11, shape=(), dtype=int64), tf.Tens...   \n",
              "99  (tf.Tensor(13, shape=(), dtype=int64), tf.Tens...   \n",
              "\n",
              "                                          id  \\\n",
              "0    tf.Tensor(b'0', shape=(), dtype=string)   \n",
              "1    tf.Tensor(b'1', shape=(), dtype=string)   \n",
              "2    tf.Tensor(b'2', shape=(), dtype=string)   \n",
              "3    tf.Tensor(b'3', shape=(), dtype=string)   \n",
              "4    tf.Tensor(b'4', shape=(), dtype=string)   \n",
              "..                                       ...   \n",
              "95  tf.Tensor(b'95', shape=(), dtype=string)   \n",
              "96  tf.Tensor(b'96', shape=(), dtype=string)   \n",
              "97  tf.Tensor(b'97', shape=(), dtype=string)   \n",
              "98  tf.Tensor(b'98', shape=(), dtype=string)   \n",
              "99  tf.Tensor(b'99', shape=(), dtype=string)   \n",
              "\n",
              "                                             pos_tags  \\\n",
              "0   (tf.Tensor(19, shape=(), dtype=int64), tf.Tens...   \n",
              "1   (tf.Tensor(20, shape=(), dtype=int64), tf.Tens...   \n",
              "2   (tf.Tensor(9, shape=(), dtype=int64), tf.Tenso...   \n",
              "3   (tf.Tensor(11, shape=(), dtype=int64), tf.Tens...   \n",
              "4   (tf.Tensor(8, shape=(), dtype=int64), tf.Tenso...   \n",
              "..                                                ...   \n",
              "95  (tf.Tensor(14, shape=(), dtype=int64), tf.Tens...   \n",
              "96  (tf.Tensor(25, shape=(), dtype=int64), tf.Tens...   \n",
              "97  (tf.Tensor(11, shape=(), dtype=int64), tf.Tens...   \n",
              "98  (tf.Tensor(11, shape=(), dtype=int64), tf.Tens...   \n",
              "99  (tf.Tensor(14, shape=(), dtype=int64), tf.Tens...   \n",
              "\n",
              "                                               tokens  \n",
              "0   (tf.Tensor(b'Confidence', shape=(), dtype=stri...  \n",
              "1   (tf.Tensor(b'Chancellor', shape=(), dtype=stri...  \n",
              "2   (tf.Tensor(b'But', shape=(), dtype=string), tf...  \n",
              "3   (tf.Tensor(b'This', shape=(), dtype=string), t...  \n",
              "4   (tf.Tensor(b'``', shape=(), dtype=string), tf....  \n",
              "..                                                ...  \n",
              "95  (tf.Tensor(b'After', shape=(), dtype=string), ...  \n",
              "96  (tf.Tensor(b'We', shape=(), dtype=string), tf....  \n",
              "97  (tf.Tensor(b'No', shape=(), dtype=string), tf....  \n",
              "98  (tf.Tensor(b'The', shape=(), dtype=string), tf...  \n",
              "99  (tf.Tensor(b'Over', shape=(), dtype=string), t...  \n",
              "\n",
              "[100 rows x 4 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "ds = tfds.load('huggingface:conll2000')\n",
        "\n",
        "train_df = pd.DataFrame(ds['train'])\n",
        "\n",
        "train_df.head(100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "555caa09a6714a63a9cdee39264291f7",
        "deepnote_cell_height": 178.34375,
        "deepnote_cell_type": "markdown",
        "id": "K1Ugs16Kg-NN",
        "tags": []
      },
      "source": [
        "First, we need to create a vocabulary. Our dataset is already tokenized. However, we need to assign ids to them in order to input them to the embedding layer. We also need the number of embeddings (`num_embeddings`) for the size of our lookup table of `nn.Embedding`.\n",
        "\n",
        "Thus, we will iterate over all sentences replace them with ids and the mapping to our vocabulary. It'll be handy to have two different mappings, from id to token, as well as, from token to id. Note that we will add a special token `<unk>` with id `0` for words that are unknown (that are not in the training dataset but could possibly be in the test dataset)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "ef26b718c8654c7cb211c7542430ee79",
        "deepnote_cell_height": 74.78125,
        "deepnote_cell_type": "markdown",
        "id": "GEAzvX3gg-NS",
        "tags": []
      },
      "source": [
        "Now, let's use PyTorch's `Dataset` and `DataLoader` to help us batching our data. Let's also replace tokens and classes with our ids. For that, complete `get_token_ids` and `get_class_ids`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "ce970c07a9ca4b6ab5a4ee941f3492b9",
        "deepnote_cell_height": 52.390625,
        "deepnote_cell_type": "markdown",
        "id": "FSbbfJqKg-NS",
        "tags": []
      },
      "source": [
        "We will use a **batch size of 32**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cell_id": "e66f66e38e4343a8ac9237e4e9bf74e5",
        "deepnote_cell_height": 76,
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 49,
        "execution_start": 1656086903728,
        "id": "WN_p7H6Zg-NS",
        "source_hash": "f1c68216",
        "tags": []
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "a4c1832e408347d89d304e7870522878",
        "deepnote_cell_height": 74.78125,
        "deepnote_cell_type": "markdown",
        "id": "FUy3i0xRg-NS",
        "tags": []
      },
      "source": [
        "However, since our examples are of different length, we need to pad shorter examples to the length of the example with the maximum length in our batch. So, let's define a special **padding token** in our vocabulary:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "c7b65a2d6b654c8bbe59ad7432758a8a",
        "deepnote_cell_height": 119.5625,
        "deepnote_cell_type": "markdown",
        "id": "CzNmO_kKg-NS",
        "tags": []
      },
      "source": [
        "The `collate_fn` is the function that actually receives a batch and needs to add the padding tokens, then returns `src` and `tgt` as `Tensor`s of size `[B, S]` where `B` is our batch size and `S` our maximum sequence length. This function should additionally return a `mask`, a `Tensor` with binary values to indicate whether the specific element is a padding token or not (0 if it's a padding token, 1 if not), such that we can ignore padding tokens in our attention mechanism and loss calculation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cell_id": "110b64825faf4982943ed9eff63ed0ff",
        "deepnote_cell_height": 94,
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 0,
        "execution_start": 1656086903778,
        "id": "5aEJb7ZZg-NT",
        "source_hash": "50d4e2b2",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chunk_tags</th>\n",
              "      <th>id</th>\n",
              "      <th>pos_tags</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(tf.Tensor(11, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>tf.Tensor(b'0', shape=(), dtype=string)</td>\n",
              "      <td>(tf.Tensor(20, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>(tf.Tensor(b'Rockwell', shape=(), dtype=string...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(tf.Tensor(11, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>tf.Tensor(b'1', shape=(), dtype=string)</td>\n",
              "      <td>(tf.Tensor(20, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>(tf.Tensor(b'Rockwell', shape=(), dtype=string...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(tf.Tensor(11, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>tf.Tensor(b'2', shape=(), dtype=string)</td>\n",
              "      <td>(tf.Tensor(11, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>(tf.Tensor(b'These', shape=(), dtype=string), ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(tf.Tensor(13, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>tf.Tensor(b'3', shape=(), dtype=string)</td>\n",
              "      <td>(tf.Tensor(14, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>(tf.Tensor(b'Under', shape=(), dtype=string), ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(tf.Tensor(11, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>tf.Tensor(b'4', shape=(), dtype=string)</td>\n",
              "      <td>(tf.Tensor(20, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>(tf.Tensor(b'Rockwell', shape=(), dtype=string...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>(tf.Tensor(11, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>tf.Tensor(b'5', shape=(), dtype=string)</td>\n",
              "      <td>(tf.Tensor(20, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>(tf.Tensor(b'Frank', shape=(), dtype=string), ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>(tf.Tensor(11, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>tf.Tensor(b'6', shape=(), dtype=string)</td>\n",
              "      <td>(tf.Tensor(20, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>(tf.Tensor(b'Mr.', shape=(), dtype=string), tf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>(tf.Tensor(13, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>tf.Tensor(b'7', shape=(), dtype=string)</td>\n",
              "      <td>(tf.Tensor(14, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>(tf.Tensor(b'In', shape=(), dtype=string), tf....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>(tf.Tensor(11, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>tf.Tensor(b'8', shape=(), dtype=string)</td>\n",
              "      <td>(tf.Tensor(20, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>(tf.Tensor(b'SHEARSON', shape=(), dtype=string...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>(tf.Tensor(11, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>tf.Tensor(b'9', shape=(), dtype=string)</td>\n",
              "      <td>(tf.Tensor(20, shape=(), dtype=int64), tf.Tens...</td>\n",
              "      <td>(tf.Tensor(b'Thomas', shape=(), dtype=string),...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          chunk_tags  \\\n",
              "0  (tf.Tensor(11, shape=(), dtype=int64), tf.Tens...   \n",
              "1  (tf.Tensor(11, shape=(), dtype=int64), tf.Tens...   \n",
              "2  (tf.Tensor(11, shape=(), dtype=int64), tf.Tens...   \n",
              "3  (tf.Tensor(13, shape=(), dtype=int64), tf.Tens...   \n",
              "4  (tf.Tensor(11, shape=(), dtype=int64), tf.Tens...   \n",
              "5  (tf.Tensor(11, shape=(), dtype=int64), tf.Tens...   \n",
              "6  (tf.Tensor(11, shape=(), dtype=int64), tf.Tens...   \n",
              "7  (tf.Tensor(13, shape=(), dtype=int64), tf.Tens...   \n",
              "8  (tf.Tensor(11, shape=(), dtype=int64), tf.Tens...   \n",
              "9  (tf.Tensor(11, shape=(), dtype=int64), tf.Tens...   \n",
              "\n",
              "                                        id  \\\n",
              "0  tf.Tensor(b'0', shape=(), dtype=string)   \n",
              "1  tf.Tensor(b'1', shape=(), dtype=string)   \n",
              "2  tf.Tensor(b'2', shape=(), dtype=string)   \n",
              "3  tf.Tensor(b'3', shape=(), dtype=string)   \n",
              "4  tf.Tensor(b'4', shape=(), dtype=string)   \n",
              "5  tf.Tensor(b'5', shape=(), dtype=string)   \n",
              "6  tf.Tensor(b'6', shape=(), dtype=string)   \n",
              "7  tf.Tensor(b'7', shape=(), dtype=string)   \n",
              "8  tf.Tensor(b'8', shape=(), dtype=string)   \n",
              "9  tf.Tensor(b'9', shape=(), dtype=string)   \n",
              "\n",
              "                                            pos_tags  \\\n",
              "0  (tf.Tensor(20, shape=(), dtype=int64), tf.Tens...   \n",
              "1  (tf.Tensor(20, shape=(), dtype=int64), tf.Tens...   \n",
              "2  (tf.Tensor(11, shape=(), dtype=int64), tf.Tens...   \n",
              "3  (tf.Tensor(14, shape=(), dtype=int64), tf.Tens...   \n",
              "4  (tf.Tensor(20, shape=(), dtype=int64), tf.Tens...   \n",
              "5  (tf.Tensor(20, shape=(), dtype=int64), tf.Tens...   \n",
              "6  (tf.Tensor(20, shape=(), dtype=int64), tf.Tens...   \n",
              "7  (tf.Tensor(14, shape=(), dtype=int64), tf.Tens...   \n",
              "8  (tf.Tensor(20, shape=(), dtype=int64), tf.Tens...   \n",
              "9  (tf.Tensor(20, shape=(), dtype=int64), tf.Tens...   \n",
              "\n",
              "                                              tokens  \n",
              "0  (tf.Tensor(b'Rockwell', shape=(), dtype=string...  \n",
              "1  (tf.Tensor(b'Rockwell', shape=(), dtype=string...  \n",
              "2  (tf.Tensor(b'These', shape=(), dtype=string), ...  \n",
              "3  (tf.Tensor(b'Under', shape=(), dtype=string), ...  \n",
              "4  (tf.Tensor(b'Rockwell', shape=(), dtype=string...  \n",
              "5  (tf.Tensor(b'Frank', shape=(), dtype=string), ...  \n",
              "6  (tf.Tensor(b'Mr.', shape=(), dtype=string), tf...  \n",
              "7  (tf.Tensor(b'In', shape=(), dtype=string), tf....  \n",
              "8  (tf.Tensor(b'SHEARSON', shape=(), dtype=string...  \n",
              "9  (tf.Tensor(b'Thomas', shape=(), dtype=string),...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df = pd.DataFrame(ds['test'])\n",
        "\n",
        "test_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "803ef4d85f0a4e2fbcb2ee182520c7f5",
        "deepnote_cell_type": "text-cell-h3",
        "formattedRanges": [],
        "id": "Ph-EhBnDg-NT",
        "is_collapsed": false,
        "tags": []
      },
      "source": [
        "### Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "06f55de40ea248099cbf94bacf9b1268",
        "deepnote_cell_height": 74.78125,
        "deepnote_cell_type": "markdown",
        "id": "gnMIT_KZg-NT",
        "tags": []
      },
      "source": [
        "Let's build a transformer model with three layers, three attention heads and an embedding dimension of 128. Also, let's not forget to add a classification head to our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cell_id": "5f1f177f8cf343f1bd763f05a8c8703d",
        "deepnote_cell_height": 223,
        "deepnote_cell_type": "code",
        "id": "-p1GWSOpg-NT",
        "tags": []
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Exception encountered when calling layer 'attention' (type Attention).\n\nAttention layer must be called on a list of inputs, namely [query, value] or [query, value, key]. Received: <keras.src.engine.input_layer.InputLayer object at 0x7fc3e5e8c890>.\n\nCall arguments received by layer 'attention' (type Attention):\n  • inputs=<keras.src.engine.input_layer.InputLayer object at 0x7fc3e5e8c890>\n  • mask=None\n  • training=None\n  • return_attention_scores=False\n  • use_causal_mask=False",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m transformer \u001b[38;5;241m=\u001b[39m \u001b[43mstacl_transformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43memb_n\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_n\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[3], line 17\u001b[0m, in \u001b[0;36mstacl_transformer\u001b[0;34m(emb_n, hidden_n, n, h)\u001b[0m\n\u001b[1;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mSequential()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[0;32m---> 17\u001b[0m     model\u001b[38;5;241m.\u001b[39madd(\u001b[43mtransformer_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_n\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memd_n\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43memb_n\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
            "Cell \u001b[0;32mIn[2], line 13\u001b[0m, in \u001b[0;36mtransformer_block\u001b[0;34m(hidden_n, h, emd_n)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"_summary_\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    _type_: _description_\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m input_layer \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mInputLayer()\n\u001b[0;32m---> 13\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAttention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_n\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_layer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mMultiHeadAttention(hidden_n, h)(x)\n\u001b[1;32m     15\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mLayerNormalization()(x)\n",
            "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/keras/src/layers/attention/base_dense_attention.py:218\u001b[0m, in \u001b[0;36mBaseDenseAttention._validate_call_args\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    216\u001b[0m class_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m layer must be called on a list of inputs, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnamely [query, value] or [query, value, key]. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    222\u001b[0m     )\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m layer accepts inputs list of length 2 or 3, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnamely [query, value] or [query, value, key]. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(inputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    228\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'attention' (type Attention).\n\nAttention layer must be called on a list of inputs, namely [query, value] or [query, value, key]. Received: <keras.src.engine.input_layer.InputLayer object at 0x7fc3e5e8c890>.\n\nCall arguments received by layer 'attention' (type Attention):\n  • inputs=<keras.src.engine.input_layer.InputLayer object at 0x7fc3e5e8c890>\n  • mask=None\n  • training=None\n  • return_attention_scores=False\n  • use_causal_mask=False"
          ]
        }
      ],
      "source": [
        "transformer = stacl_transformer(emb_n=128, hidden_n=64, n=3, h=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "f5aafb3762974b07be3a8a89899db999",
        "deepnote_cell_height": 62,
        "deepnote_cell_type": "markdown",
        "id": "507G6VcIg-NT",
        "tags": []
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "965bfa0ea57d4052aabfdba6904f65de",
        "deepnote_cell_height": 52.390625,
        "deepnote_cell_type": "markdown",
        "id": "vbPyXVNWg-NT",
        "tags": []
      },
      "source": [
        "Initialize the **AdamW** optimizer from the `torch.optim` module and choose the most appropriate loss function for our task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "5101fa497d074916b870e1e4fe9147d4",
        "deepnote_cell_height": 79,
        "deepnote_cell_type": "code",
        "id": "ojv_8lIig-NT",
        "tags": []
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "criterion = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "de1bb8eda67644db93779c72899e588c",
        "deepnote_cell_height": 220.734375,
        "deepnote_cell_type": "markdown",
        "id": "-FRAc7Ncg-NT",
        "tags": []
      },
      "source": [
        "Build a basic training loop and train the network for three epochs.\n",
        "- Use everything we've built to far, including `train_data_loader`, `model`, `optimizer` and `criterion`.\n",
        "- At every 50th step print the average loss of the last 50 steps.\n",
        "- It is suggested to make a basic training procedure to work on the CPU first. Once it successfully runs on the CPU, you can switch to the GPU (click on change runtime and add an hardware accelerator if you use Colab) and run for the whole three epochs. Note: For this to work, you need to transfer the `model` and the input tensors to the GPU memory. This simply works by calling `.to(device)` on the model and tensors, where `device` and either be `cpu` or `cuda` (for the GPU)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "19af38a10aa64403b865dde3603d43e3",
        "deepnote_cell_height": 169,
        "deepnote_cell_type": "code",
        "id": "SiSWJoNdg-NT",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 3\n",
        "\n",
        "train, test = ds\n",
        "\n",
        "train = train.shuffle(1000).batch(BATCH_SIZE)\n",
        "test = test.batch(BATCH_SIZE)\n",
        "\n",
        "transformer.compile(optimizer=optimizer, loss=criterion, metrics=['accuracy'])\n",
        "\n",
        "transformer.train(train, epochs=EPOCHS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "2f12827ec5ad4a4ba18ae8d260857cd8",
        "deepnote_cell_height": 62,
        "deepnote_cell_type": "markdown",
        "id": "4P-yVs4eg-NT",
        "tags": []
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "23af9a15c9e84bd3bea4a62c7c7e9459",
        "deepnote_cell_height": 74.78125,
        "deepnote_cell_type": "markdown",
        "id": "pJr-yYlYg-NT",
        "tags": []
      },
      "source": [
        "Let's see what's the accuracy is of our model. Since we already implemented accuracy in the previous exercise, we'll now let you use the torchmetrics package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "18891986243d49afa9305716cbd96aa7",
        "deepnote_cell_height": 97,
        "deepnote_cell_type": "code",
        "id": "C6vMlSgog-NT",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from torchmetrics import Accuracy\n",
        "\n",
        "accuracy = Accuracy(average='micro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "1cd5f69a8dcd41f8918bc9946a1b57e3",
        "deepnote_cell_height": 52.390625,
        "deepnote_cell_type": "markdown",
        "id": "oTKFmvjdg-NT",
        "tags": []
      },
      "source": [
        "Calculate the average accuracy of all examples in the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "f73337d4e25a494e9c1b138823bc1d22",
        "deepnote_cell_height": 61,
        "deepnote_cell_type": "code",
        "id": "TLY4LmbSg-NU",
        "tags": []
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "d8a4e62ebfb64dc5a6659df362eaeb50",
        "deepnote_cell_height": 52.390625,
        "deepnote_cell_type": "markdown",
        "id": "72Rvmf64g-NU",
        "tags": []
      },
      "source": [
        "Let's also look at the accuracy **for each class separately**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "98b6c3390d1b42d2bd9b2e91608625aa",
        "deepnote_cell_height": 61,
        "deepnote_cell_type": "code",
        "id": "Y15ors_Zg-NU",
        "tags": []
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "c92bfb82034344bb9cd220de8e4e157c",
        "deepnote_cell_type": "text-cell-h2",
        "formattedRanges": [],
        "id": "-ah949XNg-NU",
        "is_collapsed": false,
        "tags": []
      },
      "source": [
        "## Positional Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "070435ca57a94f1ea6e71050d57619aa",
        "deepnote_cell_height": 119.5625,
        "deepnote_cell_type": "markdown",
        "id": "Z4c_xkEOg-NU",
        "tags": []
      },
      "source": [
        "The attention mechanism does not consider the position of the tokens which hurts its performance for many problems. We can solve this issue in several ways. We can either add a positional encoding (via trigonometric functions) or we can learn positional embeddings along the way, in a similar way as BERT does. Here, we will add learnable positional embeddings to our exisisting model with another embedding layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5ff82560d6f24630a9bed80d6b38b7f1",
        "deepnote_cell_height": 74.78125,
        "deepnote_cell_type": "markdown",
        "id": "UaS49eVMg-NU",
        "tags": []
      },
      "source": [
        "The longest sequence in our dataset has 78 tokens (you can trust us on that). So, let's set the number of embeddings for our positional embedding layer to that number. Again, you should use `nn.Embedding`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "0363608d5a9a48f5be6f2e6ddbd7397c",
        "deepnote_cell_height": 52.390625,
        "deepnote_cell_type": "markdown",
        "id": "EofIIJv9g-NU",
        "tags": []
      },
      "source": [
        "Copy the inner parts of your `Transformer` class and add positional embeddings to it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "129e0b2b46c8494c90491fe2d2e137f0",
        "deepnote_cell_height": 313,
        "deepnote_cell_type": "code",
        "id": "SdQcO8FWg-NU",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class TransformerPos(nn.Module):\n",
        "    def __init__(self, emb_n: int, pos_emb_n: int, hidden_n: int, n:int =3, h:int =2):\n",
        "        \"\"\"\n",
        "        emb_n: number of token embeddings\n",
        "        pos_emb_n: number of position embeddings\n",
        "        hidden_n: hidden dimension\n",
        "        n: number of layers\n",
        "        h: number of heads per layer\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.positional_embeddings = ...\n",
        "        ...\n",
        "\n",
        "    def forward(self):\n",
        "        ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "b398b56387f54999966ee9d22a0150b1",
        "deepnote_cell_height": 61,
        "deepnote_cell_type": "code",
        "id": "iqJyP-02g-NU",
        "tags": []
      },
      "outputs": [],
      "source": [
        "model_pos = CoNLL2000Transformer(TransformerPos(...), ...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "d8f6b79fce144176832210f7a1494288",
        "deepnote_cell_height": 62,
        "deepnote_cell_type": "markdown",
        "id": "dKvdA1-Tg-NU",
        "tags": []
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "507700c451e842c4b9dbdd02857b234d",
        "deepnote_cell_height": 74.78125,
        "deepnote_cell_type": "markdown",
        "id": "XiVnpuS9g-NU",
        "tags": []
      },
      "source": [
        "Same procedure as before. Let's reinitialize our optimizer and our loss function and run the same training loop with our new model `model_pos`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "7b2c6541371f4e99bb0acfe1212c732d",
        "deepnote_cell_height": 79,
        "deepnote_cell_type": "code",
        "id": "UIpFLadDg-NU",
        "tags": []
      },
      "outputs": [],
      "source": [
        "optimizer = ....\n",
        "criterion = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "fac3717095914132b36cbfd70c702715",
        "deepnote_cell_height": 61,
        "deepnote_cell_type": "code",
        "id": "GWfsAvWEg-NU",
        "tags": []
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "2dfedd24910c45689ed2a3d4ed804af6",
        "deepnote_cell_height": 62,
        "deepnote_cell_type": "markdown",
        "id": "l39cD9spg-NU",
        "tags": []
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "472e05fab0d149b8b269a12d8e363b85",
        "deepnote_cell_height": 52.390625,
        "deepnote_cell_type": "markdown",
        "id": "qJqyPvcYg-NU",
        "tags": []
      },
      "source": [
        "Now, let's check if our performance on the accuracy got improved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "38e0fe847e464f59b1861a749fc43811",
        "deepnote_cell_height": 61,
        "deepnote_cell_type": "code",
        "id": "34cVGPt6g-NU",
        "tags": []
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "a49fe34010574a0096a020ead994158d",
        "deepnote_cell_height": 52.390625,
        "deepnote_cell_type": "markdown",
        "id": "QujIEp6Sg-NU",
        "tags": []
      },
      "source": [
        "Again, let's also check each class. Which classes got improved the most by adding positional embeddings?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "d107d15cf5fe4ee396f6733e093873cc",
        "deepnote_cell_height": 61,
        "deepnote_cell_type": "code",
        "id": "3AF1qJXrg-NW",
        "tags": []
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "bfece568a8c1460fafd968adf1972f19",
        "deepnote_cell_height": 175.953125,
        "deepnote_cell_type": "markdown",
        "id": "GDCeRpv2g-NW",
        "tags": []
      },
      "source": [
        "As an optional task, you can play around with the model by switching out the transformer component for other architecture, e.g., LSTM, an observe the change in performance."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "deepnote": {},
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "df3e6be7-b747-492e-86ed-19bc62a6bb4c",
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
