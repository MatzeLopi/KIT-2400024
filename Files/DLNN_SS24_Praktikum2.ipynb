{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "9339153b4e8f400894090f4cdec8212f",
        "deepnote_cell_height": 82,
        "deepnote_cell_type": "markdown",
        "id": "YO8yfcw9g-NJ",
        "tags": []
      },
      "source": [
        "# Praktikum 2 - Transformer\n",
        "\n",
        "Note: the praktikums are for your own practice. They will **not be graded**!\n",
        "\n",
        "You have around one week to work on it. Then we will go over the solutions together in the praktikum time slots!\n",
        "\n",
        "Remember to make a copy of this notebook to your own Colab. Changes made directly here will not be stored!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "eef422cc65524297ab7b1220162873b0",
        "deepnote_cell_type": "text-cell-p",
        "formattedRanges": [],
        "id": "5TOgi_Bzg-NJ",
        "is_collapsed": false,
        "owner_user_id": "175a6e67-5f66-4c81-960a-2a75fbd3d9af",
        "tags": []
      },
      "source": [
        "In this exercise, you'll implement a basic encoder-only Transformer architecture with PyTorch. We will start with building the basic building blocks and then integrate them into a fully-fleged Transformer model.\n",
        "\n",
        "\n",
        "<!-- We train the model to solve a POS-Tagging problem (more on that later). In the previous exercise, you implemented your work in numpy. Now, we will switch to PyTorch, which will track the gradients for us and allows us to focus more on the network itself. -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s471ndsh0612"
      },
      "source": [
        "**Notice**: Whenenver you see an ellipsis `...`, you're supposed to insert code or text answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cell_id": "20b2dbfb9550468d85d409a5a67f64c0",
        "deepnote_cell_height": 149.375,
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 810,
        "execution_start": 1657123567236,
        "id": "sVrK6a2Ug-NK",
        "outputId": "d3695725-a2e8-4f23-abf4-b2cc1c59e977",
        "owner_user_id": "06b28ca6-80fe-4ecd-a509-50438de77bba",
        "source_hash": "2c538688",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "925794d055334d71a1874bd0928f2358",
        "deepnote_cell_height": 131.1875,
        "deepnote_cell_type": "markdown",
        "id": "TjR2oJyYg-NL",
        "tags": []
      },
      "source": [
        "Let's actually start with a few basic functions that we will need throughout the exercise, namely **Softmax** and **ReLu**.\n",
        "\n",
        "$\\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}$\n",
        "\n",
        "$\\text{ReLU}(x) = \\max(0, x)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "65d60a38ea0d41ca934e8a0f782b1672",
        "deepnote_cell_height": 70,
        "deepnote_cell_type": "markdown",
        "id": "8XMfVcTkg-NL",
        "tags": []
      },
      "source": [
        "## Transformer Block"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "090be921347b4f65a3dd0fca98b29c54",
        "deepnote_cell_height": 178.953125,
        "deepnote_cell_type": "markdown",
        "id": "fVEAAyWqg-NL",
        "tags": []
      },
      "source": [
        "A typical transformer block consists of the following\n",
        "- Multi-Head Attention\n",
        "- Layer Normalization\n",
        "- Linear Layer\n",
        "- Residual Connections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "f87bf87fea1a44bcbc2d5c044843e007",
        "deepnote_cell_height": 353,
        "deepnote_cell_type": "markdown",
        "id": "BTd1mOgog-NL",
        "tags": []
      },
      "source": [
        "<center><img src=\"https://i.imgur.com/ZKgcoe4.png\" alt=\"transformer block visualization\" width=\"200\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "1c8bd5f72db0415bbca4cdd48b0ecd52",
        "deepnote_cell_type": "text-cell-p",
        "formattedRanges": [],
        "id": "nW2ik8r7g-NL",
        "is_collapsed": false,
        "tags": []
      },
      "source": [
        "In the next few subsections, we will build these basic building blocks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "59b1b38243a84b5c9571ddb814cd1a49",
        "deepnote_cell_height": 62,
        "deepnote_cell_type": "markdown",
        "id": "oGRxC5PFg-NL",
        "tags": []
      },
      "source": [
        "### Multi-Head Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "a2a24844affe40a89f26ef6ca0346276",
        "deepnote_cell_height": 88.78125,
        "deepnote_cell_type": "markdown",
        "id": "H0BU5sqdg-NL",
        "tags": []
      },
      "source": [
        "Multi-Head Attention concatenates the outputs of several so called **attention heads**.\n",
        "\n",
        "$\\textrm{MHA}(Q,K,V) = \\textrm{Concat}(H_1,...,H_h)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "ef2e9b876ee44b69a993f15856b206e9",
        "deepnote_cell_height": 376.15625,
        "deepnote_cell_type": "markdown",
        "id": "Y_sx5d4Og-NL",
        "tags": []
      },
      "source": [
        "<center><img src=\"https://www.tensorflow.org/images/tutorials/transformer/multi_head_attention.png\" width=300>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "a045d2caec3e4020a7bb3fee5680442b",
        "deepnote_cell_height": 233.90625,
        "deepnote_cell_type": "markdown",
        "id": "JKGGbtSPg-NL",
        "tags": []
      },
      "source": [
        "One attention head consists of linear projections for each of $Q, K$ and $V$ and an attention mechanism called **Scaled Dot-Product Attention**. The attention mechanism scales down the dot products by $\\sqrt{d_k}$.\n",
        "\n",
        "$\\textrm{Attention}(Q,K,V)=\\textrm{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V$\n",
        "\n",
        "\n",
        "\n",
        "If we assume that $q$ and $v$ are $d_k$-dimensional vectors and its components are independent random variables with mean $0$ and a variance of $d_k$, then their dot product has a mean of $0$ and variance of $d_k$. It is preferred to have a variance of $1$ and that's why we scale them down by $\\sqrt{d_k}$.\n",
        "\n",
        "The dot product $q \\cdot v$ resembles a measure of similarity.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "9495e574d00e4d3798368384c6b3825b",
        "deepnote_cell_height": 421.609375,
        "deepnote_cell_type": "markdown",
        "id": "EpX3rsbmg-NL",
        "tags": []
      },
      "source": [
        "<center><img src=\"https://www.tensorflow.org/images/tutorials/transformer/scaled_attention.png\" width=\"350\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "e3ed8097791f458a85f3aabfd0756d28",
        "deepnote_cell_height": 119.5625,
        "deepnote_cell_type": "markdown",
        "id": "fSpgDtHkg-NL",
        "tags": []
      },
      "source": [
        "Let's start implementing these components. Note that our classes inherit from PyTorch's `nn.Module`. These modules allow us to hold our parameters and easily move them to the GPU (with `.to(...)`). It also let's us define the computation that is performed at every call, in the `forward()` method. For example, when we have an `Attention` module, initialize it like `attention = Attention(...)`, we are able to call it with `attention(Q, K, V)` (it'll execute the `forward` function in an optimized way)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "96fa5effdd954c498f1efa8cd0580bc3",
        "deepnote_cell_height": 62,
        "deepnote_cell_type": "markdown",
        "id": "qECREjDKg-NM",
        "tags": []
      },
      "source": [
        "### Layer Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "fba0740f863c4787aa23494388944b49",
        "deepnote_cell_height": 141.953125,
        "deepnote_cell_type": "markdown",
        "id": "9RDdbMIag-NM",
        "tags": []
      },
      "source": [
        "Layer normalization is when the values are normalized across the feature dimension, independently for each sample in the batch. For that, first calculate mean and standard-deviation across the feature dimension and then scale them appropriately such that the mean is 0 and the standard deviation is 1. Introduce **two sets of learnable parameters**, one for shifting the mean (addition) and one for scaling the variance (multiplication) the normalized features (i.e., two parameters for each feature). Tip: Use `nn.Parameter` for that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5b0e5f8055a945929dd74b990ecd2a89",
        "deepnote_cell_height": 91.5,
        "deepnote_cell_type": "markdown",
        "id": "BULHLwVBg-NM",
        "tags": []
      },
      "source": [
        "$y_{\\textrm{norm}}=\\frac{x-\\mu}{\\sqrt{\\sigma+\\epsilon}}$\n",
        "\n",
        "$y=y_{\\textrm{norm}}\\cdot\\beta+\\alpha$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "f96e811cce6d457f85eead1edae4692f",
        "deepnote_cell_height": 92.390625,
        "deepnote_cell_type": "markdown",
        "id": "TnL2XBOGg-NM",
        "tags": []
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.stack.imgur.com/E3104.png\" alt=\"visualization of layer norm vs. batch norm\" width=\"420\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "246bb7a8b64f4596b26778aa9ce5bc85",
        "deepnote_cell_height": 62,
        "deepnote_cell_type": "markdown",
        "id": "MirW6JCAg-NM",
        "tags": []
      },
      "source": [
        "### Transformer Block"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "93c32b55767c46049ffb13bc012bb500",
        "deepnote_cell_height": 52.390625,
        "deepnote_cell_type": "markdown",
        "id": "iHMXP6nHg-NM",
        "tags": []
      },
      "source": [
        "Here, we bring all ingredients together into a single module. Don't forget to add the residual connections. Let's use a 2-layer MLP with ReLU activation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5HcIuJTKHCiq"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Transformer\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"Transformer\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 22\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m     21\u001b[0m model \u001b[38;5;241m=\u001b[39m transformer(\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\matze\\anaconda3\\envs\\cs-tensorflow\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\matze\\anaconda3\\envs\\cs-tensorflow\\Lib\\site-packages\\keras\\src\\models\\model.py:254\u001b[0m, in \u001b[0;36mModel.summary\u001b[1;34m(self, line_length, positions, print_fn, expand_nested, show_trainable, layer_range)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;129m@traceback_utils\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_traceback\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msummary\u001b[39m(\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    222\u001b[0m     layer_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    223\u001b[0m ):\n\u001b[0;32m    224\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prints a string summary of the network.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \n\u001b[0;32m    226\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;124;03m        ValueError: if `summary()` is called before the model is built.\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 254\u001b[0m     \u001b[43msummary_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_summary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mline_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mline_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpositions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpositions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprint_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpand_nested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_nested\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_trainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_trainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\matze\\anaconda3\\envs\\cs-tensorflow\\Lib\\site-packages\\keras\\src\\utils\\summary_utils.py:338\u001b[0m, in \u001b[0;36mprint_summary\u001b[1;34m(model, line_length, positions, print_fn, expand_nested, show_trainable, layer_range)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;66;03m# Print the to the console.\u001b[39;00m\n\u001b[0;32m    337\u001b[0m console\u001b[38;5;241m.\u001b[39mprint(bold_text(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrich\u001b[38;5;241m.\u001b[39mmarkup\u001b[38;5;241m.\u001b[39mescape(model\u001b[38;5;241m.\u001b[39mname)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m--> 338\u001b[0m \u001b[43mconsole\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    339\u001b[0m console\u001b[38;5;241m.\u001b[39mprint(\n\u001b[0;32m    340\u001b[0m     bold_text(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Total params: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;241m+\u001b[39m highlight_number(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_count\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreadable_memory_size(total_memory_size)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    343\u001b[0m )\n\u001b[0;32m    344\u001b[0m console\u001b[38;5;241m.\u001b[39mprint(\n\u001b[0;32m    345\u001b[0m     bold_text(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Trainable params: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;241m+\u001b[39m highlight_number(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainable_count\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreadable_memory_size(trainable_memory_size)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    348\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\matze\\anaconda3\\envs\\cs-tensorflow\\Lib\\site-packages\\rich\\console.py:1673\u001b[0m, in \u001b[0;36mConsole.print\u001b[1;34m(self, sep, end, style, justify, overflow, no_wrap, emoji, markup, highlight, width, height, crop, soft_wrap, new_line_start, *objects)\u001b[0m\n\u001b[0;32m   1671\u001b[0m     crop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m render_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_render_hooks[:]\n\u001b[1;32m-> 1673\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderables\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collect_renderables\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1676\u001b[0m \u001b[43m        \u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhighlight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhighlight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1682\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1683\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhook\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrender_hooks\u001b[49m\u001b[43m:\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\matze\\anaconda3\\envs\\cs-tensorflow\\Lib\\site-packages\\rich\\console.py:865\u001b[0m, in \u001b[0;36mConsole.__exit__\u001b[1;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type: Any, exc_value: Any, traceback: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Exit buffer context.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 865\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exit_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\matze\\anaconda3\\envs\\cs-tensorflow\\Lib\\site-packages\\rich\\console.py:823\u001b[0m, in \u001b[0;36mConsole._exit_buffer\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Leave buffer context, and render content if required.\"\"\"\u001b[39;00m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer_index \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 823\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\matze\\anaconda3\\envs\\cs-tensorflow\\Lib\\site-packages\\rich\\console.py:2007\u001b[0m, in \u001b[0;36mConsole._check_buffer\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_jupyter:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjupyter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display\n\u001b[1;32m-> 2007\u001b[0m     \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2008\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m   2009\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\matze\\anaconda3\\envs\\cs-tensorflow\\Lib\\site-packages\\rich\\jupyter.py:91\u001b[0m, in \u001b[0;36mdisplay\u001b[1;34m(segments, text)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display \u001b[38;5;28;01mas\u001b[39;00m ipython_display\n\u001b[1;32m---> 91\u001b[0m     \u001b[43mipython_display\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjupyter_renderable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;66;03m# Handle the case where the Console has force_jupyter=True,\u001b[39;00m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;66;03m# but IPython is not installed.\u001b[39;00m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\matze\\anaconda3\\envs\\cs-tensorflow\\Lib\\site-packages\\IPython\\core\\display_functions.py:305\u001b[0m, in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m metadata:\n\u001b[0;32m    303\u001b[0m             \u001b[38;5;66;03m# kwarg-specified metadata gets precedence\u001b[39;00m\n\u001b[0;32m    304\u001b[0m             _merge(md_dict, metadata)\n\u001b[1;32m--> 305\u001b[0m         \u001b[43mpublish_display_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmd_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m display_id:\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DisplayHandle(display_id)\n",
            "File \u001b[1;32mc:\\Users\\matze\\anaconda3\\envs\\cs-tensorflow\\Lib\\site-packages\\IPython\\core\\display_functions.py:93\u001b[0m, in \u001b[0;36mpublish_display_data\u001b[1;34m(data, metadata, source, transient, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transient:\n\u001b[0;32m     91\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransient\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m transient\n\u001b[1;32m---> 93\u001b[0m \u001b[43mdisplay_pub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\matze\\anaconda3\\envs\\cs-tensorflow\\Lib\\site-packages\\ipykernel\\zmqshell.py:103\u001b[0m, in \u001b[0;36mZMQDisplayPublisher.publish\u001b[1;34m(self, data, metadata, transient, update)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish\u001b[39m(\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     83\u001b[0m     data,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     86\u001b[0m     update\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     87\u001b[0m ):\n\u001b[0;32m     88\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Publish a display-data message\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m        If True, send an update_display_data message instead of display_data.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flush_streams\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    105\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m {}\n",
            "File \u001b[1;32mc:\\Users\\matze\\anaconda3\\envs\\cs-tensorflow\\Lib\\site-packages\\ipykernel\\zmqshell.py:66\u001b[0m, in \u001b[0;36mZMQDisplayPublisher._flush_streams\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_flush_streams\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     65\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"flush IO Streams prior to display\"\"\"\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m     \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mflush()\n",
            "File \u001b[1;32mc:\\Users\\matze\\anaconda3\\envs\\cs-tensorflow\\Lib\\site-packages\\ipykernel\\iostream.py:604\u001b[0m, in \u001b[0;36mOutStream.flush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"trigger actual zmq send\u001b[39;00m\n\u001b[0;32m    594\u001b[0m \n\u001b[0;32m    595\u001b[0m \u001b[38;5;124;03msend will happen in the background thread\u001b[39;00m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    598\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\n\u001b[0;32m    599\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mthread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    602\u001b[0m ):\n\u001b[0;32m    603\u001b[0m     \u001b[38;5;66;03m# request flush on the background thread\u001b[39;00m\n\u001b[1;32m--> 604\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpub_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flush\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    605\u001b[0m     \u001b[38;5;66;03m# wait for flush to actually get through, if we can.\u001b[39;00m\n\u001b[0;32m    606\u001b[0m     evt \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mEvent()\n",
            "File \u001b[1;32mc:\\Users\\matze\\anaconda3\\envs\\cs-tensorflow\\Lib\\site-packages\\ipykernel\\iostream.py:267\u001b[0m, in \u001b[0;36mIOPubThread.schedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_events\u001b[38;5;241m.\u001b[39mappend(f)\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;66;03m# wake event thread (message content is ignored)\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event_pipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    269\u001b[0m     f()\n",
            "File \u001b[1;32mc:\\Users\\matze\\anaconda3\\envs\\cs-tensorflow\\Lib\\site-packages\\zmq\\sugar\\socket.py:696\u001b[0m, in \u001b[0;36mSocket.send\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    689\u001b[0m         data \u001b[38;5;241m=\u001b[39m zmq\u001b[38;5;241m.\u001b[39mFrame(\n\u001b[0;32m    690\u001b[0m             data,\n\u001b[0;32m    691\u001b[0m             track\u001b[38;5;241m=\u001b[39mtrack,\n\u001b[0;32m    692\u001b[0m             copy\u001b[38;5;241m=\u001b[39mcopy \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    693\u001b[0m             copy_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_threshold,\n\u001b[0;32m    694\u001b[0m         )\n\u001b[0;32m    695\u001b[0m     data\u001b[38;5;241m.\u001b[39mgroup \u001b[38;5;241m=\u001b[39m group\n\u001b[1;32m--> 696\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mzmq\\\\backend\\\\cython\\\\socket.pyx:742\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mzmq\\\\backend\\\\cython\\\\socket.pyx:789\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mzmq\\\\backend\\\\cython\\\\socket.pyx:250\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\matze\\anaconda3\\envs\\cs-tensorflow\\Lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd:13\u001b[0m, in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def transformer_block(hidden_n: int, heads: int, inputs):\n",
        "    x = layers.MultiHeadAttention(num_heads=heads, key_dim=hidden_n // heads)(\n",
        "        inputs, inputs\n",
        "    )\n",
        "    x = layers.LayerNormalization()(x + inputs)\n",
        "    x = layers.Dense(hidden_n, activation=\"relu\")(x)\n",
        "    x = layers.LayerNormalization()(x + inputs)\n",
        "    return x\n",
        "\n",
        "\n",
        "def transformer(emb_n: int, hidden_n: int, n: int = 3, h: int = 2, name: str = \"Model\"):\n",
        "    inputs = keras.Input(shape=(None,))\n",
        "    x = layers.Embedding(emb_n, hidden_n)(inputs)\n",
        "    for _ in range(n):\n",
        "        x = transformer_block(hidden_n, h, x)\n",
        "    outputs = layers.GlobalAveragePooling1D()(x)\n",
        "    try:\n",
        "        model = keras.Model(inputs, outputs, name=name)\n",
        "    except Exception:\n",
        "        model = keras.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "model = transformer(1000, 128, 3, 2, \"Transformer\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "add8b0cdf6ef4a79bf2a71788029d617",
        "deepnote_cell_height": 70,
        "deepnote_cell_type": "markdown",
        "id": "voJMCeBmg-NM",
        "tags": []
      },
      "source": [
        "## A Simple Transformer Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "0215525d6258493485ff71f3496128a2",
        "deepnote_cell_height": 74.78125,
        "deepnote_cell_type": "markdown",
        "id": "2G8hVCmvg-NM",
        "tags": []
      },
      "source": [
        "Let's stack our transformer blocks and add an embedding layer for a simple transformer architecture. You are allowed to use `nn.Embedding` here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "46e6832e31434597932051c2d7d833db",
        "deepnote_cell_height": 74.78125,
        "deepnote_cell_type": "markdown",
        "id": "GA6K1Ohxg-NN",
        "tags": []
      },
      "source": [
        "Part-Of-Speech-Tagging (**POS-Tagging**) is a **sequence labeling problem** where we categorize words in a text in correspondence with a particular part of speech (e.g., \"noun\" or \"adjective\"). A few examples and classes are shown in the following table:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "0b933b07b931423dae80af31abe46b69",
        "deepnote_cell_height": 200.734375,
        "deepnote_cell_type": "markdown",
        "id": "lQImsUJDg-NN",
        "tags": []
      },
      "source": [
        "|  POS Tag  |  Description  |  Examples  |\n",
        "|-----------|------------|------------|\n",
        "|  NN | Noun (singular, common) | mass, wind, ...  |\n",
        "|  NNP | Noun (singular, proper) | Obama, Liverpool, ...  |\n",
        "| CD  | Numeral (cardinal)  | 1890, 0.5, ...  |\n",
        "|  DT | Determiner  | all, any, ... |\n",
        "| JJ | Adjective (ordinal) | oiled, third, ... |\n",
        "... many more"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "c1ea426748d34a2891270fb4c9189387",
        "deepnote_cell_type": "text-cell-h3",
        "formattedRanges": [],
        "id": "KbJ-P7_tg-NN",
        "is_collapsed": false,
        "tags": []
      },
      "source": [
        "### CoNLL2000 Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "ec19498428f042a09867d13bfcbbeaf1",
        "deepnote_cell_height": 52.390625,
        "deepnote_cell_type": "markdown",
        "id": "9BhWiVRwg-NN",
        "tags": []
      },
      "source": [
        "Let's load our dataset which is the **CoNLL2000 dataset** and look at an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cell_id": "56f8d97328eb45808c642c232c18ddeb",
        "deepnote_cell_height": 329.375,
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 3449,
        "execution_start": 1657123575378,
        "id": "PhCtZ0Ygg-NN",
        "outputId": "ee561fdc-ac6c-478c-ce10-2bb8b7bba91f",
        "source_hash": "c7ccc53b",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\matze\\anaconda3\\envs\\cs-tensorflow\\Lib\\site-packages\\torchtext\\__init__.py:7: SyntaxWarning: invalid escape sequence '\\ '\n",
            "  \"\\n/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \\n\"\n"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "[WinError 127] Die angegebene Prozedur wurde nicht gefunden",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CoNLL2000Chunking\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m train_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(CoNLL2000Chunking()[\u001b[38;5;241m0\u001b[39m], columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwords\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos_tags\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchunk\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
            "File \u001b[1;32mc:\\Users\\matze\\anaconda3\\envs\\cs-tensorflow\\Lib\\site-packages\\torchtext\\__init__.py:18\u001b[0m\n\u001b[0;32m     15\u001b[0m     _WARN \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# the following import has to happen first in order to load the torchtext C++ library\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _extension  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     20\u001b[0m _TEXT_BUCKET \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://download.pytorch.org/models/text/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     22\u001b[0m _CACHE_DIR \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(_get_torch_home(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
            "File \u001b[1;32mc:\\Users\\matze\\anaconda3\\envs\\cs-tensorflow\\Lib\\site-packages\\torchtext\\_extension.py:64\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _torchtext  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m \u001b[43m_init_extension\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\matze\\anaconda3\\envs\\cs-tensorflow\\Lib\\site-packages\\torchtext\\_extension.py:58\u001b[0m, in \u001b[0;36m_init_extension\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _mod_utils\u001b[38;5;241m.\u001b[39mis_module_available(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchtext._torchtext\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchtext C++ Extension is not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 58\u001b[0m \u001b[43m_load_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlibtorchtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# This import is for initializing the methods registered via PyBind11\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# This has to happen after the base library is loaded\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _torchtext\n",
            "File \u001b[1;32mc:\\Users\\matze\\anaconda3\\envs\\cs-tensorflow\\Lib\\site-packages\\torchtext\\_extension.py:50\u001b[0m, in \u001b[0;36m_load_lib\u001b[1;34m(lib)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\matze\\anaconda3\\envs\\cs-tensorflow\\Lib\\site-packages\\torch\\_ops.py:1295\u001b[0m, in \u001b[0;36m_Ops.load_library\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m   1290\u001b[0m path \u001b[38;5;241m=\u001b[39m _utils_internal\u001b[38;5;241m.\u001b[39mresolve_library_path(path)\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dl_open_guard():\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;66;03m# Import the shared library into the process, thus running its\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m     \u001b[38;5;66;03m# static (global) initialization code in order to register custom\u001b[39;00m\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;66;03m# operators with the JIT.\u001b[39;00m\n\u001b[1;32m-> 1295\u001b[0m     \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_libraries\u001b[38;5;241m.\u001b[39madd(path)\n",
            "File \u001b[1;32mc:\\Users\\matze\\anaconda3\\envs\\cs-tensorflow\\Lib\\ctypes\\__init__.py:379\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
            "\u001b[1;31mOSError\u001b[0m: [WinError 127] Die angegebene Prozedur wurde nicht gefunden"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchtext.datasets import CoNLL2000Chunking\n",
        "import pandas as pd\n",
        "\n",
        "train_df = pd.DataFrame(CoNLL2000Chunking()[0], columns=['words', 'pos_tags', 'chunk'])\n",
        "test_df = pd.DataFrame(CoNLL2000Chunking()[1], columns=['words', 'pos_tags', 'chunk'])\n",
        "\n",
        "train_src, train_tgt = train_df['words'].tolist(), train_df['pos_tags'].tolist()\n",
        "test_src, test_tgt = test_df['words'].tolist(), test_df['pos_tags'].tolist()\n",
        "\n",
        "print(train_src[0])\n",
        "print(train_tgt[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "555caa09a6714a63a9cdee39264291f7",
        "deepnote_cell_height": 178.34375,
        "deepnote_cell_type": "markdown",
        "id": "K1Ugs16Kg-NN",
        "tags": []
      },
      "source": [
        "First, we need to create a vocabulary. Our dataset is already tokenized. However, we need to assign ids to them in order to input them to the embedding layer. We also need the number of embeddings (`num_embeddings`) for the size of our lookup table of `nn.Embedding`.\n",
        "\n",
        "Thus, we will iterate over all sentences replace them with ids and the mapping to our vocabulary. It'll be handy to have two different mappings, from id to token, as well as, from token to id. Note that we will add a special token `<unk>` with id `0` for words that are unknown (that are not in the training dataset but could possibly be in the test dataset)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "9b665796e64d4aa694d1718b5156294d",
        "deepnote_cell_height": 148,
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 1512,
        "execution_start": 1656084179768,
        "id": "dIJxB8g6g-NS",
        "output_cleared": true,
        "source_hash": "2276b8b9",
        "tags": []
      },
      "outputs": [],
      "source": [
        "vocabulary_id2token : dict = {0: '<unk>'}\n",
        "vocabulary_token2id : dict = {'<unk>': 0}\n",
        "\n",
        "for sentence in train_src:\n",
        "    ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "eed144592b0a4aa9a752fab5230b27e6",
        "deepnote_cell_height": 52.390625,
        "deepnote_cell_type": "markdown",
        "id": "sa8c2lw4g-NS",
        "tags": []
      },
      "source": [
        "Let's do the same for our classes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "a4401fdd42024ef9b0af6c95af4ff963",
        "deepnote_cell_height": 133,
        "deepnote_cell_type": "code",
        "id": "-OXjcd_6g-NS",
        "tags": []
      },
      "outputs": [],
      "source": [
        "classes_id2name : dict = {}\n",
        "classes_name2id : dict = {}\n",
        "\n",
        "for sentence in *[train_src, test_src]:\n",
        "    ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "ef26b718c8654c7cb211c7542430ee79",
        "deepnote_cell_height": 74.78125,
        "deepnote_cell_type": "markdown",
        "id": "GEAzvX3gg-NS",
        "tags": []
      },
      "source": [
        "Now, let's use PyTorch's `Dataset` and `DataLoader` to help us batching our data. Let's also replace tokens and classes with our ids. For that, complete `get_token_ids` and `get_class_ids`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "33964355330b45ad98f64b88799e8672",
        "deepnote_cell_height": 508,
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 2,
        "execution_start": 1656333952181,
        "id": "G9HM-s2Zg-NS",
        "source_hash": "a6bcb220",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def get_token_ids(src: list[str]) -> list[int]:\n",
        "    ...\n",
        "\n",
        "def get_class_ids(tgt: list[str]) -> list[int]:\n",
        "    ...\n",
        "\n",
        "class ConllDataset(Dataset):\n",
        "  def __init__(self, src, tgt):\n",
        "        self.src = src\n",
        "        self.tgt = tgt\n",
        "\n",
        "  def __len__(self):\n",
        "        return len(self.src)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        src = self.src[index]\n",
        "        tgt = self.tgt[index]\n",
        "\n",
        "        return {\n",
        "            'src': get_token_ids(src),\n",
        "            'tgt': get_class_ids(tgt),\n",
        "        }\n",
        "\n",
        "train_dataset = ConllDataset(train_src, train_tgt)\n",
        "test_dataset = ConllDataset(test_src, test_tgt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "ce970c07a9ca4b6ab5a4ee941f3492b9",
        "deepnote_cell_height": 52.390625,
        "deepnote_cell_type": "markdown",
        "id": "FSbbfJqKg-NS",
        "tags": []
      },
      "source": [
        "We will use a **batch size of 32**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "e66f66e38e4343a8ac9237e4e9bf74e5",
        "deepnote_cell_height": 76,
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 49,
        "execution_start": 1656086903728,
        "id": "WN_p7H6Zg-NS",
        "source_hash": "f1c68216",
        "tags": []
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "a4c1832e408347d89d304e7870522878",
        "deepnote_cell_height": 74.78125,
        "deepnote_cell_type": "markdown",
        "id": "FUy3i0xRg-NS",
        "tags": []
      },
      "source": [
        "However, since our examples are of different length, we need to pad shorter examples to the length of the example with the maximum length in our batch. So, let's define a special **padding token** in our vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "00825cb3c6194a91b8cc03eee1a61e7c",
        "deepnote_cell_height": 115,
        "deepnote_cell_type": "code",
        "id": "Iz8dYm5Bg-NS",
        "tags": []
      },
      "outputs": [],
      "source": [
        "padding_token = ...\n",
        "\n",
        "vocabulary_id2token ...\n",
        "vocabulary_token2id ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "c7b65a2d6b654c8bbe59ad7432758a8a",
        "deepnote_cell_height": 119.5625,
        "deepnote_cell_type": "markdown",
        "id": "CzNmO_kKg-NS",
        "tags": []
      },
      "source": [
        "The `collate_fn` is the function that actually receives a batch and needs to add the padding tokens, then returns `src` and `tgt` as `Tensor`s of size `[B, S]` where `B` is our batch size and `S` our maximum sequence length. This function should additionally return a `mask`, a `Tensor` with binary values to indicate whether the specific element is a padding token or not (0 if it's a padding token, 1 if not), such that we can ignore padding tokens in our attention mechanism and loss calculation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "9266354695a646ebbd776e4290baa002",
        "deepnote_cell_height": 238,
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 0,
        "execution_start": 1656086903777,
        "id": "ww6x2u7Ug-NT",
        "source_hash": "d3107fb6",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch: list[dict]) -> dict[str, Tensor]:\n",
        "    \"\"\"\n",
        "    batch: list of dictionaries with keys src and tgt (as defined in ConllDataset)\n",
        "    \"\"\"\n",
        "    ...\n",
        "    return {\n",
        "        'src': src,\n",
        "        'tgt': tgt,\n",
        "        'mask': mask,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "27c262f705004bac83e8306a99ba8bcb",
        "deepnote_cell_height": 52.390625,
        "deepnote_cell_type": "markdown",
        "id": "A5QZZJjdg-NT",
        "tags": []
      },
      "source": [
        "With that, we can use PyTorch's `DataLoader` which will shuffle and batch our data automatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "110b64825faf4982943ed9eff63ed0ff",
        "deepnote_cell_height": 94,
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 0,
        "execution_start": 1656086903778,
        "id": "5aEJb7ZZg-NT",
        "source_hash": "50d4e2b2",
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_data_loader = DataLoader(train_dataset, collate_fn=collate_fn, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_data_loader = DataLoader(test_dataset, collate_fn=collate_fn, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "803ef4d85f0a4e2fbcb2ee182520c7f5",
        "deepnote_cell_type": "text-cell-h3",
        "formattedRanges": [],
        "id": "Ph-EhBnDg-NT",
        "is_collapsed": false,
        "tags": []
      },
      "source": [
        "### Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "06f55de40ea248099cbf94bacf9b1268",
        "deepnote_cell_height": 74.78125,
        "deepnote_cell_type": "markdown",
        "id": "gnMIT_KZg-NT",
        "tags": []
      },
      "source": [
        "Let's build a transformer model with three layers, three attention heads and an embedding dimension of 128. Also, let's not forget to add a classification head to our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "5f1f177f8cf343f1bd763f05a8c8703d",
        "deepnote_cell_height": 223,
        "deepnote_cell_type": "code",
        "id": "-p1GWSOpg-NT",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class CoNLL2000Transformer(nn.Module):\n",
        "    def __init__(self, transformer, ...):\n",
        "        super().__init__()\n",
        "        self.transformer = transformer\n",
        "        self.classification_layer = ...\n",
        "\n",
        "    def forward(self, X, mask):\n",
        "        ...\n",
        "\n",
        "model = CoNLL2000Transformer(Transformer(...), ...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "f5aafb3762974b07be3a8a89899db999",
        "deepnote_cell_height": 62,
        "deepnote_cell_type": "markdown",
        "id": "507G6VcIg-NT",
        "tags": []
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "965bfa0ea57d4052aabfdba6904f65de",
        "deepnote_cell_height": 52.390625,
        "deepnote_cell_type": "markdown",
        "id": "vbPyXVNWg-NT",
        "tags": []
      },
      "source": [
        "Initialize the **AdamW** optimizer from the `torch.optim` module and choose the most appropriate loss function for our task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "5101fa497d074916b870e1e4fe9147d4",
        "deepnote_cell_height": 79,
        "deepnote_cell_type": "code",
        "id": "ojv_8lIig-NT",
        "tags": []
      },
      "outputs": [],
      "source": [
        "optimizer = ...\n",
        "criterion = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "de1bb8eda67644db93779c72899e588c",
        "deepnote_cell_height": 220.734375,
        "deepnote_cell_type": "markdown",
        "id": "-FRAc7Ncg-NT",
        "tags": []
      },
      "source": [
        "Build a basic training loop and train the network for three epochs.\n",
        "- Use everything we've built to far, including `train_data_loader`, `model`, `optimizer` and `criterion`.\n",
        "- At every 50th step print the average loss of the last 50 steps.\n",
        "- It is suggested to make a basic training procedure to work on the CPU first. Once it successfully runs on the CPU, you can switch to the GPU (click on change runtime and add an hardware accelerator if you use Colab) and run for the whole three epochs. Note: For this to work, you need to transfer the `model` and the input tensors to the GPU memory. This simply works by calling `.to(device)` on the model and tensors, where `device` and either be `cpu` or `cuda` (for the GPU)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "19af38a10aa64403b865dde3603d43e3",
        "deepnote_cell_height": 169,
        "deepnote_cell_type": "code",
        "id": "SiSWJoNdg-NT",
        "tags": []
      },
      "outputs": [],
      "source": [
        "DEVICE = 'cpu' # later replace with 'cuda' for GPU\n",
        "EPOCHS = 3\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "2f12827ec5ad4a4ba18ae8d260857cd8",
        "deepnote_cell_height": 62,
        "deepnote_cell_type": "markdown",
        "id": "4P-yVs4eg-NT",
        "tags": []
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "23af9a15c9e84bd3bea4a62c7c7e9459",
        "deepnote_cell_height": 74.78125,
        "deepnote_cell_type": "markdown",
        "id": "pJr-yYlYg-NT",
        "tags": []
      },
      "source": [
        "Let's see what's the accuracy is of our model. Since we already implemented accuracy in the previous exercise, we'll now let you use the torchmetrics package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "18891986243d49afa9305716cbd96aa7",
        "deepnote_cell_height": 97,
        "deepnote_cell_type": "code",
        "id": "C6vMlSgog-NT",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from torchmetrics import Accuracy\n",
        "\n",
        "accuracy = Accuracy(average='micro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "1cd5f69a8dcd41f8918bc9946a1b57e3",
        "deepnote_cell_height": 52.390625,
        "deepnote_cell_type": "markdown",
        "id": "oTKFmvjdg-NT",
        "tags": []
      },
      "source": [
        "Calculate the average accuracy of all examples in the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "f73337d4e25a494e9c1b138823bc1d22",
        "deepnote_cell_height": 61,
        "deepnote_cell_type": "code",
        "id": "TLY4LmbSg-NU",
        "tags": []
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "d8a4e62ebfb64dc5a6659df362eaeb50",
        "deepnote_cell_height": 52.390625,
        "deepnote_cell_type": "markdown",
        "id": "72Rvmf64g-NU",
        "tags": []
      },
      "source": [
        "Let's also look at the accuracy **for each class separately**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "98b6c3390d1b42d2bd9b2e91608625aa",
        "deepnote_cell_height": 61,
        "deepnote_cell_type": "code",
        "id": "Y15ors_Zg-NU",
        "tags": []
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "c92bfb82034344bb9cd220de8e4e157c",
        "deepnote_cell_type": "text-cell-h2",
        "formattedRanges": [],
        "id": "-ah949XNg-NU",
        "is_collapsed": false,
        "tags": []
      },
      "source": [
        "## Positional Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "070435ca57a94f1ea6e71050d57619aa",
        "deepnote_cell_height": 119.5625,
        "deepnote_cell_type": "markdown",
        "id": "Z4c_xkEOg-NU",
        "tags": []
      },
      "source": [
        "The attention mechanism does not consider the position of the tokens which hurts its performance for many problems. We can solve this issue in several ways. We can either add a positional encoding (via trigonometric functions) or we can learn positional embeddings along the way, in a similar way as BERT does. Here, we will add learnable positional embeddings to our exisisting model with another embedding layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5ff82560d6f24630a9bed80d6b38b7f1",
        "deepnote_cell_height": 74.78125,
        "deepnote_cell_type": "markdown",
        "id": "UaS49eVMg-NU",
        "tags": []
      },
      "source": [
        "The longest sequence in our dataset has 78 tokens (you can trust us on that). So, let's set the number of embeddings for our positional embedding layer to that number. Again, you should use `nn.Embedding`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "0363608d5a9a48f5be6f2e6ddbd7397c",
        "deepnote_cell_height": 52.390625,
        "deepnote_cell_type": "markdown",
        "id": "EofIIJv9g-NU",
        "tags": []
      },
      "source": [
        "Copy the inner parts of your `Transformer` class and add positional embeddings to it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "129e0b2b46c8494c90491fe2d2e137f0",
        "deepnote_cell_height": 313,
        "deepnote_cell_type": "code",
        "id": "SdQcO8FWg-NU",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class TransformerPos(nn.Module):\n",
        "    def __init__(self, emb_n: int, pos_emb_n: int, hidden_n: int, n:int =3, h:int =2):\n",
        "        \"\"\"\n",
        "        emb_n: number of token embeddings\n",
        "        pos_emb_n: number of position embeddings\n",
        "        hidden_n: hidden dimension\n",
        "        n: number of layers\n",
        "        h: number of heads per layer\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.positional_embeddings = ...\n",
        "        ...\n",
        "\n",
        "    def forward(self):\n",
        "        ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "b398b56387f54999966ee9d22a0150b1",
        "deepnote_cell_height": 61,
        "deepnote_cell_type": "code",
        "id": "iqJyP-02g-NU",
        "tags": []
      },
      "outputs": [],
      "source": [
        "model_pos = CoNLL2000Transformer(TransformerPos(...), ...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "d8f6b79fce144176832210f7a1494288",
        "deepnote_cell_height": 62,
        "deepnote_cell_type": "markdown",
        "id": "dKvdA1-Tg-NU",
        "tags": []
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "507700c451e842c4b9dbdd02857b234d",
        "deepnote_cell_height": 74.78125,
        "deepnote_cell_type": "markdown",
        "id": "XiVnpuS9g-NU",
        "tags": []
      },
      "source": [
        "Same procedure as before. Let's reinitialize our optimizer and our loss function and run the same training loop with our new model `model_pos`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "7b2c6541371f4e99bb0acfe1212c732d",
        "deepnote_cell_height": 79,
        "deepnote_cell_type": "code",
        "id": "UIpFLadDg-NU",
        "tags": []
      },
      "outputs": [],
      "source": [
        "optimizer = ....\n",
        "criterion = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "fac3717095914132b36cbfd70c702715",
        "deepnote_cell_height": 61,
        "deepnote_cell_type": "code",
        "id": "GWfsAvWEg-NU",
        "tags": []
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "2dfedd24910c45689ed2a3d4ed804af6",
        "deepnote_cell_height": 62,
        "deepnote_cell_type": "markdown",
        "id": "l39cD9spg-NU",
        "tags": []
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "472e05fab0d149b8b269a12d8e363b85",
        "deepnote_cell_height": 52.390625,
        "deepnote_cell_type": "markdown",
        "id": "qJqyPvcYg-NU",
        "tags": []
      },
      "source": [
        "Now, let's check if our performance on the accuracy got improved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "38e0fe847e464f59b1861a749fc43811",
        "deepnote_cell_height": 61,
        "deepnote_cell_type": "code",
        "id": "34cVGPt6g-NU",
        "tags": []
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "a49fe34010574a0096a020ead994158d",
        "deepnote_cell_height": 52.390625,
        "deepnote_cell_type": "markdown",
        "id": "QujIEp6Sg-NU",
        "tags": []
      },
      "source": [
        "Again, let's also check each class. Which classes got improved the most by adding positional embeddings?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "d107d15cf5fe4ee396f6733e093873cc",
        "deepnote_cell_height": 61,
        "deepnote_cell_type": "code",
        "id": "3AF1qJXrg-NW",
        "tags": []
      },
      "outputs": [],
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "bfece568a8c1460fafd968adf1972f19",
        "deepnote_cell_height": 175.953125,
        "deepnote_cell_type": "markdown",
        "id": "GDCeRpv2g-NW",
        "tags": []
      },
      "source": [
        "As an optional task, you can play around with the model by switching out the transformer component for other architecture, e.g., LSTM, an observe the change in performance."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "deepnote": {},
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "df3e6be7-b747-492e-86ed-19bc62a6bb4c",
    "kernelspec": {
      "display_name": "cs-tensorflow",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
